{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf idf\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('merged_newsapi_data.csv')  \n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=1000,  \n",
    "    stop_words='english',  \n",
    "    ngram_range=(1, 2)  \n",
    ")\n",
    "X = vectorizer.fit_transform(df['Lemmatized'])\n",
    "\n",
    "k = 5  \n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "plt.title('TF-IDF + K-Means Clustering (PCA Reduced)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop Keywords per Cluster:\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    cluster_words = kmeans.cluster_centers_[i].argsort()[-10:][::-1]  # Top 10 words\n",
    "    print(f\"Cluster {i}:\", [feature_names[w] for w in cluster_words])\n",
    "\n",
    "print(\"\\nSample Titles per Cluster:\")\n",
    "for cluster_num in range(k):\n",
    "    print(f\"\\nCluster {cluster_num}:\")\n",
    "    print(df[df['Cluster'] == cluster_num]['Title'].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('merged_newsapi_data.csv') \n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Lemmatized'])\n",
    "\n",
    "k = 5  \n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X)\n",
    "\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "plt.title('K-Means Clustering (TF-IDF + PCA)')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top Keywords per Cluster:\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    cluster_words = kmeans.cluster_centers_[i].argsort()[-10:][::-1]\n",
    "    print(f\"Cluster {i}: {[feature_names[w] for w in cluster_words]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('merged_newsapi_data.csv')  \n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['Lemmatized'])\n",
    "\n",
    "cosine_dist = 1 - cosine_similarity(X)\n",
    "\n",
    "Z = linkage(cosine_dist, method='ward')\n",
    "\n",
    "num_labels = len(df)\n",
    "numeric_labels = list(range(1, num_labels + 1))  \n",
    "\n",
    "plt.figure(figsize=(16, 6))  \n",
    "dendro = dendrogram(Z, labels=numeric_labels, leaf_rotation=90, leaf_font_size=7)  \n",
    "\n",
    "plt.title('Hierarchical Clustering Dendrogram (Cosine Distance)')\n",
    "plt.xlabel('Document Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "mapping = {idx: title for idx, title in zip(numeric_labels, df['Title'])}\n",
    "\n",
    "print(\"\\n=== Document Index Mapping ===\")\n",
    "for idx, title in mapping.items():\n",
    "    print(f\"{idx}: {title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # For 3D plotting\n",
    "\n",
    "# Install missing packages if needed\n",
    "try:\n",
    "    import plotly\n",
    "except ImportError:\n",
    "    !pip install plotly nbformat --quiet\n",
    "    import plotly\n",
    "\n",
    "df = pd.read_csv('merged_newsapi_data.csv') \n",
    "\n",
    "# 1. TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(df['Lemmatized'])\n",
    "\n",
    "# 2. Dimensionality Reduction to 3D using PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "# 3. K-Means Clustering on the 3D PCA-reduced data\n",
    "k = 5  # Number of clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add clusters and PCA coordinates to DataFrame\n",
    "df['Cluster'] = clusters\n",
    "df['PCA1'] = X_pca[:, 0]  # First principal component\n",
    "df['PCA2'] = X_pca[:, 1]  # Second principal component\n",
    "df['PCA3'] = X_pca[:, 2]  # Third principal component\n",
    "\n",
    "# 4. 3D Visualization using Matplotlib\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k']\n",
    "for i in range(k):\n",
    "    cluster_data = df[df['Cluster'] == i]\n",
    "    ax.scatter(cluster_data['PCA1'], \n",
    "               cluster_data['PCA2'], \n",
    "               cluster_data['PCA3'], \n",
    "               c=colors[i], \n",
    "               label=f'Cluster {i}',\n",
    "               alpha=0.6)\n",
    "\n",
    "ax.set_title('K-Means Clustering on 3D PCA-Reduced TF-IDF Vectors')\n",
    "ax.set_xlabel('PCA Component 1')\n",
    "ax.set_ylabel('PCA Component 2')\n",
    "ax.set_zlabel('PCA Component 3')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5. Print cluster keywords\n",
    "print(\"\\nTop Keywords per Cluster:\")\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    # Get indices of documents in this cluster\n",
    "    cluster_indices = df[df['Cluster'] == i].index\n",
    "    # Get TF-IDF vectors for this cluster and average them\n",
    "    cluster_tfidf = X_tfidf[cluster_indices].mean(axis=0)\n",
    "    # Get top 10 words\n",
    "    top_words = cluster_tfidf.argsort()[0, -10:][::-1]\n",
    "    print(f\"Cluster {i}: {[feature_names[w] for w in top_words.flatten()]}\")\n",
    "\n",
    "# 6. Print sample titles from each cluster\n",
    "print(\"\\nSample Titles per Cluster:\")\n",
    "for i in range(k):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    print(df[df['Cluster'] == i]['Title'].head(3).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('merged_newsapi_data.csv')\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(df['Lemmatized'])\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_tfidf.toarray())\n",
    "\n",
    "k_values = [3, 5, 7]\n",
    "results = {}\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_pca)\n",
    "    \n",
    "    results[k] = {\n",
    "        'model': kmeans,\n",
    "        'clusters': clusters,\n",
    "        'silhouette': silhouette_score(X_pca, clusters)\n",
    "    }\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    for i in range(k):\n",
    "        ax.scatter(X_pca[clusters==i, 0], \n",
    "                   X_pca[clusters==i, 1], \n",
    "                   X_pca[clusters==i, 2], \n",
    "                   label=f'Cluster {i}',\n",
    "                   alpha=0.6)\n",
    "    \n",
    "    ax.set_title(f'K-Means Clustering (k={k})\\nSilhouette: {results[k][\"silhouette\"]:.3f}')\n",
    "    ax.set_xlabel('PCA 1')\n",
    "    ax.set_ylabel('PCA 2')\n",
    "    ax.set_zlabel('PCA 3')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, k in enumerate(k_values):\n",
    "    plt.subplot(3, 1, i+1)\n",
    "    \n",
    "    silhouette_vals = silhouette_samples(X_pca, results[k]['clusters'])\n",
    "    \n",
    "    y_lower = 10\n",
    "    for j in range(k):\n",
    "        jth_cluster_silhouette = silhouette_vals[results[k]['clusters'] == j]\n",
    "        jth_cluster_silhouette.sort()\n",
    "        \n",
    "        y_upper = y_lower + jth_cluster_silhouette.shape[0]\n",
    "        \n",
    "        color = plt.cm.nipy_spectral(float(j) / k)\n",
    "        plt.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, jth_cluster_silhouette,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        \n",
    "        plt.text(-0.05, y_lower + 0.5 * jth_cluster_silhouette.shape[0], str(j))\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    plt.title(f'Silhouette Plot for k={k}')\n",
    "    plt.xlabel(\"Silhouette coefficient values\")\n",
    "    plt.ylabel(\"Cluster label\")\n",
    "    plt.axvline(x=results[k]['silhouette'], color=\"red\", linestyle=\"--\")\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "Z = linkage(X_pca, method='ward')\n",
    "dendrogram(Z, truncate_mode='lastp', p=20, show_leaf_counts=True)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Document Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "best_k = 3\n",
    "kmeans = results[best_k]['model']\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"\\nTop Keywords per Cluster (k=3):\")\n",
    "for i in range(best_k):\n",
    "    cluster_mask = (results[best_k]['clusters'] == i)\n",
    "    cluster_tfidf = X_tfidf[cluster_mask].mean(axis=0)\n",
    "    top_words = cluster_tfidf.argsort()[0, -10:][::-1]\n",
    "    print(f\"Cluster {i}: {[feature_names[w] for w in top_words.flatten()]}\")\n",
    "    \n",
    "    print(\"Sample Titles:\")\n",
    "    print(df[cluster_mask]['Title'].head(3).to_string(index=False))\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
